{
 "metadata": {
  "kernelspec": {
   "name": "glue_pyspark",
   "display_name": "Glue PySpark",
   "language": "python"
  },
  "language_info": {
   "name": "Python_Glue_Session",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "pygments_lexer": "python3",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AWS Glue Studio Notebook\n",
    "##### Glue job with PySpark to clean and transform citibike data and load into S3 data lake\n"
   ],
   "metadata": {
    "editable": true,
    "trusted": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, to_timestamp, year, month, dayofmonth, hour, date_format, lit, when, count, avg, udf\n",
    ")\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "import math\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Citibike Data Processing\") \\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define Schema for the Dataset\n",
    "schema = StructType([\n",
    "    StructField(\"ride_id\", StringType(), True),\n",
    "    StructField(\"rideable_type\", StringType(), True),\n",
    "    StructField(\"started_at\", TimestampType(), True),\n",
    "    StructField(\"ended_at\", TimestampType(), True),\n",
    "    StructField(\"start_station_name\", StringType(), True),\n",
    "    StructField(\"start_station_id\", StringType(), True),\n",
    "    StructField(\"end_station_name\", StringType(), True),\n",
    "    StructField(\"end_station_id\", StringType(), True),\n",
    "    StructField(\"start_lat\", DoubleType(), True),\n",
    "    StructField(\"start_lng\", DoubleType(), True),\n",
    "    StructField(\"end_lat\", DoubleType(), True),\n",
    "    StructField(\"end_lng\", DoubleType(), True),\n",
    "    StructField(\"member_casual\", StringType(), True)\n",
    "])"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Raw Data from S3\n",
    "raw_data_path = \"s3://citibike-df/inbound-data/*.csv\"\n",
    "df = spark.read.schema(schema).option(\"header\", \"true\").csv(raw_data_path)\n"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define Haversine Formula to Calculate Distance\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Register Haversine function as a UDF\n",
    "haversine_udf = udf(haversine, DoubleType())"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Data Cleaning and Transformation\n",
    "processed_df = df.withColumnRenamed(\"member_casual\", \"user_type\") \\\n",
    "    .withColumn(\"trip_duration_seconds\", \n",
    "                (col(\"ended_at\").cast(\"long\") - col(\"started_at\").cast(\"long\"))) \\\n",
    "    .withColumn(\"start_year\", year(col(\"started_at\"))) \\\n",
    "    .withColumn(\"start_month\", month(col(\"started_at\"))) \\\n",
    "    .withColumn(\"start_day\", dayofmonth(col(\"started_at\"))) \\\n",
    "    .withColumn(\"start_hour\", hour(col(\"started_at\"))) \\\n",
    "    .withColumn(\"end_year\", year(col(\"ended_at\"))) \\\n",
    "    .withColumn(\"end_month\", month(col(\"ended_at\"))) \\\n",
    "    .withColumn(\"end_day\", dayofmonth(col(\"ended_at\"))) \\\n",
    "    .withColumn(\"end_hour\", hour(col(\"ended_at\"))) \\\n",
    "    .withColumn(\"user_type\", \n",
    "                when(col(\"user_type\") == \"member\", \"Subscriber\")\n",
    "                .otherwise(\"Customer\")) \\\n",
    "    .withColumn(\"start_station_id\", col(\"start_station_id\").cast(StringType())) \\\n",
    "    .withColumn(\"end_station_id\", col(\"end_station_id\").cast(StringType())) \\\n",
    "    .withColumn(\"start_lat\", col(\"start_lat\").cast(DoubleType())) \\\n",
    "    .withColumn(\"start_lng\", col(\"start_lng\").cast(DoubleType())) \\\n",
    "    .withColumn(\"end_lat\", col(\"end_lat\").cast(DoubleType())) \\\n",
    "    .withColumn(\"end_lng\", col(\"end_lng\").cast(DoubleType())) \\\n",
    "    .dropDuplicates([\"ride_id\"])  # Remove duplicate rows based on ride_id\n"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Handle Missing Values\n",
    "processed_df = processed_df.na.fill({\n",
    "    \"start_station_name\": \"Unknown\",\n",
    "    \"start_station_id\": \"Unknown\",\n",
    "    \"end_station_name\": \"Unknown\",\n",
    "    \"end_station_id\": \"Unknown\",\n",
    "    \"start_lat\": 0.0,\n",
    "    \"start_lng\": 0.0,\n",
    "    \"end_lat\": 0.0,\n",
    "    \"end_lng\": 0.0\n",
    "})"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate Trip Distance using Haversine Formula\n",
    "processed_df = processed_df.withColumn(\n",
    "    \"trip_distance_km\",\n",
    "    haversine_udf(col(\"start_lat\"), col(\"start_lng\"), col(\"end_lat\"), col(\"end_lng\"))\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Dimension Tables\n",
    "# 1. Stations Dimension\n",
    "stations = processed_df.select(\n",
    "    col(\"start_station_id\").alias(\"station_id\"),\n",
    "    col(\"start_station_name\").alias(\"station_name\"),\n",
    "    col(\"start_lat\").alias(\"latitude\"),\n",
    "    col(\"start_lng\").alias(\"longitude\")\n",
    ").distinct()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "stations.show()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": "+----------+--------------------+------------+-------------+\n|station_id|        station_name|    latitude|    longitude|\n+----------+--------------------+------------+-------------+\n|     JC103|      Journal Square|    40.73367|     -74.0625|\n|     HB102|Hoboken Terminal ...|40.736116886|-74.029208183|\n|     JC063|      Jackson Square|    40.71113|     -74.0789|\n|     JC009|       Hamilton Park|40.727452755| -74.04429698|\n|     HB506|    Grand St & 14 St|40.753990173|-74.031709194|\n|     JC052|  Liberty Light Rail|40.711340785|-74.055756807|\n|     JC065|              Dey St|40.737742424|-74.067027569|\n|     HB201|12 St & Sinatra Dr N|40.750844717|-74.024120808|\n|     HB402|   Madison St & 1 St|40.738869905|-74.039157629|\n|     HB603|8 St & Washington St|40.745940685|-74.028149962|\n|     HB303|   Clinton St & 7 St|40.745452762|-74.033394217|\n|     JC103|      Journal Square|  40.7337327|-74.062520027|\n|     JC072|        Morris Canal|40.712231278|-74.038221717|\n|     JC103|      Journal Square|40.733755946|-74.062389255|\n|     HB603|8 St & Washington St|40.745958209|-74.028219581|\n|     JC076|         Dixon Mills|40.721590519|-74.050032258|\n|     HB105|City Hall - Washi...| 40.73719573|-74.031074643|\n|     HB105|City Hall - Washi...|40.737151861|-74.031048298|\n|     HB102|Hoboken Terminal ...|40.736243606|-74.029574633|\n|     JC072|        Morris Canal| 40.71227777|-74.038198113|\n+----------+--------------------+------------+-------------+\nonly showing top 20 rows\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Users Dimension\n",
    "users = processed_df.select(\n",
    "    col(\"ride_id\").alias(\"user_id\"),  # Assuming ride_id can be used as user_id since we don't have the user data\n",
    "    lit(1990).alias(\"birth_year\"),    # Placeholder for birth year\n",
    "    lit(\"Unknown\").alias(\"gender\")    # Placeholder for gender\n",
    ").distinct()\n"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Time Dimension\n",
    "# Set legacy time parser policy\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "time_dim = processed_df.select(\n",
    "    col(\"started_at\").alias(\"time_id\"),\n",
    "    year(col(\"started_at\")).alias(\"year\"),\n",
    "    month(col(\"started_at\")).alias(\"month\"),\n",
    "    dayofmonth(col(\"started_at\")).alias(\"day\"),\n",
    "    hour(col(\"started_at\")).alias(\"hour\"),\n",
    "    date_format(col(\"started_at\"), \"u\").alias(\"day_of_week\"),  # 'u' for day of the week (1 = Monday, 7 = Sunday)\n",
    "    when(date_format(col(\"started_at\"), \"u\").isin([6, 7]), True).otherwise(False).alias(\"is_weekend\")\n",
    ").distinct()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Bikes Dimension (Placeholder)\n",
    "bikes = processed_df.select(\n",
    "    col(\"ride_id\").alias(\"bike_id\"),  # Assuming ride_id can be used as bike_id\n",
    "    lit(\"classic\").alias(\"bike_type\"),  # Placeholder for bike type\n",
    "    lit(\"Unknown\").alias(\"manufacturer\"),  # Placeholder for manufacturer\n",
    "    lit(\"2020-01-01\").alias(\"purchase_date\")  # Placeholder for purchase date\n",
    ").distinct()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Weather Dimension (Placeholder)\n",
    "# Fetch weather data using an OpenWeatherMap API \n",
    "def fetch_weather(lat, lng, timestamp):\n",
    "    api_key = \"855152b9f44ec9bbf0c3c1f9d2f0b534\"\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lng}&dt={timestamp}&appid={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        weather_data = response.json()\n",
    "        return {\n",
    "            \"temperature_c\": weather_data[\"main\"][\"temp\"] - 273.15,  # Convert Kelvin to Celsius\n",
    "            \"precipitation_mm\": weather_data.get(\"rain\", {}).get(\"1h\", 0.0),\n",
    "            \"weather_condition\": weather_data[\"weather\"][0][\"main\"]\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"temperature_c\": 0.0,\n",
    "            \"precipitation_mm\": 0.0,\n",
    "            \"weather_condition\": \"Unknown\"\n",
    "        }\n"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Weather Dimension\n",
    "weather_df = processed_df.select(\n",
    "    col(\"started_at\").alias(\"time_id\"),\n",
    "    col(\"start_lat\").alias(\"latitude\"),\n",
    "    col(\"start_lng\").alias(\"longitude\")\n",
    ").distinct()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "weather_df = weather_df.limit(5)\n",
    "weather_df.show()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": "+-------------------+-----------------+------------------+\n|            time_id|         latitude|         longitude|\n+-------------------+-----------------+------------------+\n|2023-11-05 09:59:04|       40.7112423|       -74.0557013|\n|2023-11-05 01:25:24|     40.719288945|     -74.034209609|\n|2023-11-20 06:01:05|     40.713478446|     -74.062786818|\n|2023-11-27 20:59:22|40.73721535335381|-74.02886540972803|\n|2023-11-03 14:20:25|     40.714554071|     -74.042777896|\n+-------------------+-----------------+------------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Fetch weather data for each row (this can be optimized further)\n",
    "weather_data = []\n",
    "for row in weather_df.collect():\n",
    "    weather = fetch_weather(row[\"latitude\"], row[\"longitude\"], int(row[\"time_id\"].timestamp()))\n",
    "    weather_data.append({\n",
    "        \"time_id\": row[\"time_id\"],\n",
    "        \"temperature_c\": weather[\"temperature_c\"],\n",
    "        \"precipitation_mm\": weather[\"precipitation_mm\"],\n",
    "        \"weather_condition\": weather[\"weather_condition\"]\n",
    "    })\n",
    "weather_dim = spark.createDataFrame(weather_data)"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "weather_dim.show()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": "+----------------+-------------------+-------------------+-----------------+\n|precipitation_mm|      temperature_c|            time_id|weather_condition|\n+----------------+-------------------+-------------------+-----------------+\n|             0.0| -1.589999999999975|2023-11-28 19:10:15|             Snow|\n|             0.0| -1.919999999999959|2023-11-16 08:44:32|             Snow|\n|             0.0|-1.6899999999999977|2023-11-07 18:25:03|             Snow|\n|             0.0|-1.9099999999999682|2023-11-27 14:36:28|             Snow|\n|             0.0| -1.849999999999966|2023-11-07 11:52:45|             Snow|\n+----------------+-------------------+-------------------+-----------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Prepare Trip Fact Table\n",
    "trips = processed_df.select(\n",
    "    col(\"ride_id\").alias(\"trip_id\"),\n",
    "    col(\"start_station_id\"),\n",
    "    col(\"end_station_id\"),\n",
    "    col(\"started_at\").alias(\"start_time_id\"),\n",
    "    col(\"ended_at\").alias(\"end_time_id\"),\n",
    "    col(\"ride_id\").alias(\"user_id\"),  # Assuming ride_id can be used as user_id\n",
    "    col(\"ride_id\").alias(\"bike_id\"),  # Assuming ride_id can be used as bike_id\n",
    "    col(\"trip_duration_seconds\"),\n",
    "    col(\"trip_distance_km\"),\n",
    "    col(\"user_type\")\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trips.show()"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save Dimension Tables to S3\n",
    "dimensions_path = \"s3://citibike-df/outbound-data/dimensions/\"\n",
    "stations.write.mode(\"overwrite\").parquet(f\"{dimensions_path}stations_dim\")\n",
    "users.write.mode(\"overwrite\").parquet(f\"{dimensions_path}users_dim\")\n",
    "time_dim.write.mode(\"overwrite\").parquet(f\"{dimensions_path}time_dim\")\n",
    "bikes.write.mode(\"overwrite\").parquet(f\"{dimensions_path}bikes_dim\")\n",
    "weather_dim.write.mode(\"overwrite\").parquet(f\"{dimensions_path}weather_dim\")"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Save Fact Table to S3\n",
    "fact_path = \"s3://citibike-df/outbound-data/fact/\"\n",
    "trips.write.mode(\"overwrite\").parquet(f\"{fact_path}trips_fact\")"
   ],
   "metadata": {
    "trusted": true,
    "tags": []
   },
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Stop Spark Session\n",
    "spark.stop()"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
